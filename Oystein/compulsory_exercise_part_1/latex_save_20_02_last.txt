
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{esint}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{ dsfont }
\usepackage{hyperref}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[font={small,it}]{caption}
\usepackage{caption}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage[euler]{textgreek}
\graphicspath{{./plots/}}
\usepackage{biblatex}
\addbibresource{reff.bib}
\usepackage{caption}
\usepackage{subfig}
\usepackage{subcaption}
\usepackage{float}
\usepackage[font=small,labelfont=bf]{caption}
\setcounter{secnumdepth}{5}
\usepackage[autocite=footnote,notetype=foot+end,style=authortitle-ibid]{biblatex}
\usepackage{amsmath}
\DeclareMathOperator{\sign}{sign}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={150mm,230mm},
 left=30mm,
 top=30mm,
 }
\usepackage{amsmath}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

\usepackage{mathtools}

\newcommand{\expect}{\operatorname{E}\expectarg}
\DeclarePairedDelimiterX{\expectarg}[1]{[}{]}{%
  \ifnum\currentgrouptype=16 \else\begingroup\fi
  \activatebar#1
  \ifnum\currentgrouptype=16 \else\endgroup\fi
}

\newcommand{\innermid}{\nonscript\;\delimsize\vert\nonscript\;}
\newcommand{\activatebar}{%
  \begingroup\lccode`\~=`\|
  \lowercase{\endgroup\let~}\innermid 
  \mathcode`|=\string"8000
}

\title{Compulsory exercise - STK4051}
\author{Øystein Høistad Bruce}
\date{February 2022}

\begin{document}
\maketitle

\begin{figure}[H]
    \centering
    \includegraphics[width=8.5cm]{uio.jpeg}
\end{figure}

\begin{center}
    \Large
    Department of Mathematics 
    \normalsize
\end{center}


\newpage

\tableofcontents
\newpage

\section{Exercise 1 (Lp-regularization)}
Simplified regression model:

\begin{align}
\label{simple_regression}
    y_i = \beta_i + \epsilon_i \quad i=1, ..., n
\end{align}
where $y_i$ is the data, $\beta_i$ are the parameters, and $\epsilon_i \sim \mathcal{N}(0, 1^2) $ is an error term. The probability distribution of $\epsilon_i$ is:

\begin{align}
    p(\epsilon_i) = \frac{1}{\sqrt{2\pi}} \, \exp{\{-\epsilon_i^2/2\}} \qquad -\infty < \epsilon_i < \infty
\end{align}

\subsection*{a) Derive the maximum likelihood estimator for $\beta_i$, i = 1, ..., n} 

The probability of getting $y_i$ (given current estimates on beta) is the probability that a random sample from the standard normal distribution to be $y_i - \beta_i$. The likelihood can then be written as:

\begin{align*}
    L(\theta | y) 
    &= \prod_{i=1}^{n} p(y_i - \beta_i)
\end{align*}
further, we get the following expression for the log-likelihood:

\begin{align*}
    l(\theta | y)
    &= \log \, \{ L(\theta | y) \}
    = \log \, \bigg\{ \prod_{i=1}^{n} p(y_i - \beta_i) \bigg\} \\
    &= \sum_{i=1}^{n} \log \{ p(y_i - \beta_i)\} \\
    &= \sum_{i=1}^{n} -\log \{ \sqrt{2 \pi} \} + \frac{(y_i - \beta_i)^2}{2}
\end{align*}
\noindent
Now, we are ready to find the maximum likelihood estimator for $\beta_i$, by finding the derivative of the log-likelihood function w.r.t. $\beta_i$ and set it equal to zero. 

\begin{align*}
    \frac{\partial l(\theta | y)}{\partial \beta_i}
    &= \frac{2(y_i - \beta_i)}{2} = (y_i - \beta_i) \stackrel{!}{=} 0
\end{align*}
\noindent
The maximum likelihood estimator, will then be the following:
\begin{align}
    \hat{\beta_i} = y_i \qquad i = 1, ..., n
\end{align}


\subsection*{b)}
An alternative estimator is derived using a penalized least squares, by solving the optimization problem:

\begin{align}
    \min_{\beta} \, \{ -l(\beta | y) + \frac{\gamma}{p} \| \beta \|_p^p \}
\end{align}
where $l$ is the log-likelihood, $\gamma$ is a regularization parameter and

\begin{align*}
    \| \beta \|_p^p = \sum_{i=1}^{n} |\beta_i|^p
\end{align*}

\noindent
\textbf{Show that}
\begin{align}
    f_{p, \gamma} (\beta_i) = \beta_i + \gamma \cdot \sign (\beta_i) |\beta_i|^{p-1}
\end{align}
where $f_{p, y}(\beta_i)$ should satisfy 

\begin{align}
\label{function_f_equal_y}
    f_{p, y}(\beta_i) = y_i \quad i = 1, ..., n
\end{align}

\noindent
\textbf{Answer}\\
We will first find the derivative of the expression we want to minimize w.r.t. $\beta_i$, then set the expression to 0. 

\begin{align*}
    \frac{\partial}{\partial \beta_i} \left( -l(\beta | y) + \frac{\gamma}{p} \| \beta \|_p^p \right)
    &= -(y_i - \beta_i) + \frac{\gamma}{p} \, p |\beta_i|^{p-1} 
    \, \frac{\partial |\beta_i|}{\beta_i} \\
    &= -y_i + \beta_i + \gamma |\beta_i|^{p-1} 
    \, \frac{\partial |\beta_i|}{\beta_i} \\
    &= -y_i + \beta_i + \gamma |\beta_i|^{p-1} 
    \, \sign ( \beta_i ) \stackrel{!}{=} 0
\end{align*}
\noindent
Then, we solve for $y_i$ and get the result we were gonna prove:

\begin{align*}
    y_i = \beta_i + \gamma |\beta_i|^{p-1} 
    \, \sign ( \beta_i ) \qquad i = 1, ..., n
\end{align*}

\subsection*{c)} 
Let $\gamma = \{ 1, 0.2 \}$, plot the function $f_{p, \gamma} (\beta)$ for $p = \{ 1.1, 2, 5, 100\}$ on the interval $[-5, 5]$. Give an interpretation of the result. \\


\noindent
Plot the inverse function by flipping the order of the arguments in the plotting function. Give an interpretation of the result. 


\subsection*{d)}
Implement a function which finds the root of expression (\ref{function_f_equal_y}). \\
\noindent

Testing the algorithm for $\gamma = 1$ and $p = \{ 1.1, 2, 100 \}$, and evaluate the results for $y \in [-5, 5]$.

\subsection*{e)}
Now, we are ready for doing the different estimations with actual data. The data we are given are y, and the ground truth values for beta, $\beta_{GT}$. \\

\noindent
Firstly, we will look at the penalized regression. We want to compute $\hat{\beta}_{\gamma, p}$ with $\gamma = 1, p = \{ 1.1, 2, 100\}$ \\

\noindent
Secondly, find the MLE estimator and compare the residuals with the previous cases. \\

\noindent
Lastly, we want to look at another way of achieve an estimator. That is:

\begin{align*}
    \hat{\beta}^{\text{Alt}}_{1, 100} = y - \hat{\beta}_{1, 100}
\end{align*}

\subsection*{f)}
In the linear regression problem, \\
\noindent
TO BE CONTINUED


\section{Exercise 2 (EM-algorithm)}
In this exercise, we will be using the data in the file \textit{sparseDataWithErrors.dat} \\

\noindent
For this exercise we will assume that $Y_i \quad i = 1, ..., n$ are independent and identically distributed according to the mixture distribution:

\begin{align}
\label{mixture_distribution}
    f(y_i) = p \cdot \phi(y_i; 0, 1^2) + (1-p) \cdot \phi (y_i; 0, \tau ^2 + 1^2)
\end{align}
where $\phi(y_i; \mu, \sigma^2)$ is the normal density with mean $\mu$ and variance $\sigma ^2$. We will now consider estimation of the parameters $\theta = (p, \tau ^2)$.

\subsection*{a) Give an expression for the likelihood of $\theta$}
The likelihood of $\theta$ can be expressed as follows:

\begin{align*}
    L(\theta | y) &= \prod_{i=1}^{n} f(y_i) \\
    &= \prod_{i=1}^{n} \left[ p \cdot \phi(y_i; 0, 1^2) + (1-p) \cdot \phi (y_i; 0, \tau ^2 + 1^2) \right]
\end{align*}

\subsection*{b) Introduce the variable $C_i$ which identifies the model $y_i$ belongs to. Give an expression for the complete log-likelihood using the pairs $(C_i, y_i)_{i=1}^{n}$}
We know that we can belong to either one of the two classes $\{ 0, 1\}$. Let class 0 be the data from the normal distribution with variance 1, and class 1 be the other one. \\

\noindent
Starting up with an expression for the complete likelihood:
\begin{align*}
    L_{\text{comp}}(\theta | (C, y)) = \prod_{i=1}^{n} \left[ \mathds{1}_{c_i = 0} \cdot \phi(y_i; 0, 1^2) + \mathds{1}_{c_i = 1} \cdot \phi (y_i; 0, \tau ^2 + 1^2) \right]
\end{align*}

\noindent
Then we get the following for the complete log-likelihood:
\begin{align*}
    l_{\text{comp}}(\theta | (C, y)) &= \log \{ L_{\text{comp}}(\theta | (C, y)) \} \\
    &= \sum_{i=1}^{n} \left[ \log \{ \mathds{1}_{c_i = 0} \cdot \phi(y_i; 0, 1^2) \} + \log \{ \mathds{1}_{c_i = 1} \cdot \phi (y_i; 0, \tau ^2 + 1^2) \} \right] \\
    &= \sum_{i=1}^{n} \left[ \mathds{1}_{c_i = 0} \log \{ \phi(y_i; 0, 1^2) \} + \mathds{1}_{c_i = 1} \log \{ \phi (y_i; 0, \tau ^2 + 1^2) \} \right] \\
    &= \sum_{i=1}^{n} \left[ \mathds{1}_{c_i = 0} \left(-\log (\sqrt{2\pi}) - \frac{y_i^2}{2} \right)
    + \mathds{1}_{c_i = 1} \left(-\log (\sqrt{2\pi} \cdot \sqrt{\tau^2+1}) - \frac{y_i^2}{2 \, (\tau^2 + 1)} \right) \right]
\end{align*}

\subsection*{c) Give an expression for $Q(\theta, \theta^{(t)})$, what is the interpretation of $Q(\theta, \theta^{(t)})$. Derive the estimates for $\theta =  (p, \tau^2)$, using $Q(\theta, \theta^{(t)})$.}

\begin{align*}
    Q(\theta, \theta^{(t)}) 
    &= E [ \, l_{\text{comp}} | y, \theta^{(t)} ] \\
    &= E \left[ \sum_{i=1}^{n} \left( \mathds{1}_{c_i = 0} \left(-\log (\sqrt{2\pi}) - \frac{y_i^2}{2} \right)
    + \mathds{1}_{c_i = 1} \left(-\log (\sqrt{2\pi} \cdot \sqrt{\tau^2+1}) - \frac{y_i^2}{2 \, (\tau^2 + 1)} \right) \right) \right] \\
    &=^1 \sum_{i=1}^{n} \left( E [\mathds{1}_{c_i = 0} | y, \theta^{(t)}] \left(-\log (\sqrt{2\pi}) - \frac{y_i^2}{2} \right)
    +  E[\mathds{1}_{c_i = 1} | y, \theta^{(t)}] \left(-\log (\sqrt{2\pi} \cdot \sqrt{\tau^2+1}) - \frac{y_i^2}{2 \, (\tau^2 + 1)} \right) \right) \\
    &=^2 \sum_{i=1}^{n} \left( p_i \left(-\log (\sqrt{2\pi}) - \frac{y_i^2}{2} \right)
    +  (1-p_i) \left(-\log (\sqrt{2\pi} \cdot \sqrt{\tau^2+1}) - \frac{y_i^2}{2 \, (\tau^2 + 1)} \right) \right) \\
    &= \sum_{i=1}^{n} \left( p_i \left(-\log (\sqrt{2\pi}) - \frac{y_i^2}{2} \right)
    +  (1-p_i) \left(-\log (\sqrt{2\pi}) - \frac{1}{2} \log (\tau^2+1) - \frac{y_i^2}{2 \, (\tau^2 + 1)} \right) \right)
\end{align*}

\noindent
\textbf{Note:}
\begin{enumerate}
    \item Expected value of a sum is the sum of the expected values. We do also have that the only thing that is stochastic in the expectation are the indicator functions. 
    \item let $p_i = P(C_i = 0 | y, \theta^{(t)})$. This will imply that $P(C_i = 1 | y, \theta^{(t)}) = 1 - P(C_i = 0 | y, \theta^{(t)}) = (1-p_i)$.
\end{enumerate}

\noindent
The Q function is taking the expected value of the complete log likelihood given both the observed data and the current estimate of the parameters we want to optimize. \\
% TODO:

\noindent
First, we will find the updating algorithm for p

\begin{align*}
    p^{(t+1)} &= 
    \frac{\sum_{i=1}^{n} p_i}{\sum_{i=1}^{n} p_i + \sum_{i=1}^{n} (1 - p_i)} 
    = \frac{\sum_{i=1}^{n} p_i}{n}
\end{align*}
where $p_i$ can be calculated as:

\begin{align*}
    p_i &= P(C_i = 0 | y_i, \theta^{(t)}) \\
    &=^1 \frac{P(C_i = 0, Y_i = y_i | \theta^{(t)})}{P(Y_i = y_i | \theta^{(t)})} \\
    &= \frac{P(Y_i = y_i | c_i=0, \theta^{(t)})P(C_i = 0 | \theta^{(t)})}{P(Y_i = y_i | \theta^{(t)})}\\
    &=^2 \frac{\phi (y_i; 0, 1^2) \cdot p^{(t)}}{\phi (y_i; 0, 1^2) \cdot p^{(t)} + \phi (y_i; 0, {\tau^2}^{(t)} + 1) \cdot (1 - p^{(t)})}\\
\end{align*}
which will make the fully algorithm for updating p as:

\begin{align*}
    p^{(t+1)} 
    &= \frac{1}{n} \sum_{i=1}^{n} \frac{\phi (y_i; 0, 1^2) \cdot p^{(t)}}{\phi (y_i; 0, 1^2) \cdot p^{(t)} + \phi (y_i; 0, {\tau^2}^{(t)} + 1) \cdot (1 - p^{(t)})}\\
\end{align*}

\noindent
\textbf{Note:}
\begin{enumerate}
    \item Bayes theorem 
    \item Law of total probability
\end{enumerate}

\noindent
Deriving the estimate for $\tau^2$ by first taking the derivative of the function Q, with respect to $\tau^2$ - and then find the parameter that set the expression to 0. 

\begin{align*}
    \frac{\partial}{\partial (\tau^2)} Q(\theta, \theta^{(t)}) 
    &= \sum_{i=1}^{n} (1-p_i) \left(- \frac{1}{2(\tau^2+1)} + \frac{y_i^2}{2 \, (\tau^2 + 1)^2} \right) \\
    &= \sum_{i=1}^{n} (1-p_i) \left(\frac{y_i^2}{2 \, (\tau^2 + 1)^2} - \frac{1}{2(\tau^2+1)}\right) \stackrel{!}{=} 0
\end{align*}

\begin{align*}
    \frac{\partial}{\partial (\tau^2)} Q(\theta, \theta^{(t)}) = 0
    \quad &\Longrightarrow \quad \sum_{i=1}^{n} (1-p_i) \left(\frac{y_i^2}{2 \, (\tau^2 + 1)^2} - \frac{1}{2(\tau^2+1)}\right) = 0 \\
    &\Longrightarrow^1 \quad \sum_{i=1}^{n} (1-p_i) \left( y_i^2 - (\tau^2 + 1) \right) = 0 \\
    &\Longrightarrow \quad \sum_{i=1}^{n} (1-p_i)y_i^2 = \sum_{i=1}^{n} (1-p_i)(\tau^2 + 1) \\
    &\Longrightarrow \quad \sum_{i=1}^{n} (1-p_i)y_i^2 = (\tau^2 + 1)\sum_{i=1}^{n} (1-p_i) \\
    &\Longrightarrow \quad \frac{\sum_{i=1}^{n} (1-p_i)y_i^2}{\sum_{i=1}^{n} (1-p_i)} = (\tau^2 + 1) \\
    &\Longrightarrow \quad \tau^2 =  \frac{\sum_{i=1}^{n} (1-p_i)y_i^2}{\sum_{i=1}^{n} (1-p_i)} - 1 \\
\end{align*}

The updating algorithm for $\tau^2$ will then be:
\begin{align}
    {\tau^2}^{(t+1)} =  \frac{\sum_{i=1}^{n} (1-p_i)y_i^2}{\sum_{i=1}^{n} (1-p_i)} - 1
\end{align}


\noindent
\textbf{Note:}
\begin{enumerate}
    \item multiplied both sides with $(\tau^2 + 1)/2$
\end{enumerate}

\subsection*{d) Implement the solution you derived in (c) as a function, and apply it to the data. What is a good initialization}

You can see the implementation in the appendix \ref{exercise_2_d_appendix}. A good initailization is #TODO


\subsection*{e) Compute a bootstrap estimate of the uncertainty of the two parameters, using the functions from (d). Sample $B=1000$ times and display scatter plot of the values}

The bootstrap method implementation can be looked up in the appendix \ref{exercise_2_e_appendix}. The bootstrap estimate of the uncertainty are: #TODO, add also scatter plot. 

\subsection*{f) Compute the observed information matrix. How can you use the observed information matrix to give an uncertainty estimate for $\theta$? Compare the result to (e)}

The code for computing the observed information matrix will be located at the appendix \ref{exercise_2_f_appendix}. # TODO: You can use the inverse of the information matrix to give an uncertainty estimate for the parameters, since the inverse of the information matrix is the covariance matrix. \\

\noindent
The computed observed information matrix and covariance matrix are as follows:
# TODO: add it. 

\subsection*{g)}

\section{Exercise 3}
Assuming that the data $Y_i$ are the same as in (\ref{simple_regression}) and that $y_i$, follows mixture distribution as in (\ref{mixture_distribution}).

\subsection*{a)}
\textbf{Use a Bayesian interpretation of $\beta_i$ and argue that}
\begin{align*}
    P(\beta_i=0|C_i=0)=1 \quad \text{and} \quad f(\beta_i | C_i = 1) = \phi(\beta_i;0,\tau^2)
\end{align*}
\textbf{Also, give an expression for $P(\beta_i = 0 | y_i = y)$}

\begin{align*}
    P(\beta_i = 0 | y_i = y)
\end{align*}

\noindent
\textbf{Answer:} We have that 

\begin{align*}
    P(\beta_i=0|C_i=0) &= \frac{P(\beta_i=0, C_i=0)}{P(C_i = 0)} \\
    &= \frac{P(\beta_i=0, C_i=0)}{p}
\end{align*}

\section{Exercise 4 (Combinatorial optimization)}
\label{exercise_4}
We will try to minimize the total time spent on delivering a product to 20 different cities.

\subsection*{a) Simulated annealing}

\noindent
The implementation of the simulated annealing algorithm can be seen in the appendix section \ref{exercise_4a_appendix}. # TODO \\

\noindent
I used this neighborhood in the search for a optimum:
\begin{align*}
    \mathcal{N}(\theta) = \{ \theta ^* \, | \, \exists \, k, j \; \text{s.t.} \;  \theta^*_k = \theta_j , \,  \theta^*_j = \theta_k
    \quad \text{and} \quad \theta^*_i = \theta_i \: \forall \: i \neq k, j \}
\end{align*}
which is an mathematical expression for switching two of the entries in the sequence. The algorithm can reach each state with this neighborhood property. Given a state we want to reach, we can start by switching the first entry to the first entry in the state we want to reach (by switching the elements in our current sequence), then we will go one with this procedure until we reach the end of the sequence. \\

\noindent
The cooling schedule I will be using is:

\begin{align*}
\label{cooling_schedule_simulated_annealing}
    \alpha(t) = 100/(t+1)
\end{align*}
where t in this context will be the iteration of the algorithm. 

\subsection*{b) TABU search}
Implementation of the algorithm will be found in the appendix (\ref{exercise_4b_appendix}). \\

\noindent
TABU search and simulated annealing are able to get to worse states, while the combinatorial optimization algorithm steepest descent will be monotonic since it will always improve (or stand at its current guess). 

\subsection*{c) Interpretation to the boss}
Manager: "Your current solution, will it be the optimal one?" \\
\\
\noindent
Øystein: "Nah, don't think so. It's like $20! = 2.43*10^{18}$ solutions to this problem, so I will not guarantee that there will not be a better solution to the optimal route" \\
\\
\noindent
Manager: "I knew it, I shouldn't hire you! \\
\\
\noindent
Øystein: "Ey boss, I can assure you that the solution I have proposed will be near the optimal solution tho. I have run the problem several times with different initial guesses, and different combinatorial optimization algorithm. My confidence on this result are based on that it has been converged to frequently, and if it converged to something else - it has always been a worse result. It's easy to see that the route it efficient with respect to the map." \\
\\
\noindent
Manager: "Oh, sorry for doubting you. You will get a raise soon." \\
\\
\noindent
Øystein: "I'm just doing my job sir"

\subsection*{d) Another lorry to help with the product transporting}
There are many solutions to this problem, but I have decided to go with this following algorithm. In each iteration, there are three possibilities (with equal probability to happen):

\begin{enumerate}
    \item Lorry 1 switches two destinations 
    \item Lorry 2 switches two destinations
    \item Switching between the lorries (one destination)
\end{enumerate}
Let $(\theta^{(1)}, \theta^{(2)})$ be the routes for the lorries. With the neighbourhoods below (\ref{first_neighbourhood}, \ref{second_neighbourhood} and \ref{third_neighbourhood}) we can't communicate with all states. Instead of changing the neighbourhoods for the states to communicate, we will rather introduce some 0's in the routes $(\theta^{(1)}, \theta^{(2)})$. These 0's can either be placed randomly or strategically (in between every number, for instance). We want to add 0's such that the length of the route is equal to the actual number of cities (20 in this case). \\

\noindent
The initial guess can for instance be random amount of destination (in random order), where every city are included in exactly one of the routes. Then add the 0's as described above. \\

\noindent
\textbf{Note:} the 0's will be skipped when first driving a route (invisible for the drivers), but will be helpful for us making the routes. These 0's may be confusing at first sight, but it will be very helpful. \\

\noindent
Let's introduce three neighbourhoods which all will be used in the final neighbourhood expression for the problem:

\begin{align*}
\label{first_neighbourhood}
    \mathcal{N}_1(\theta^{(1)}, \theta^{(2)}) &= \{ \theta^{(1)}^*, \theta^{(2)}^* \, | \, \exists \, k, j \; \text{s.t.} \;  \theta^{(1)}^*_k = \theta^{(1)}_j , \,  \theta^{(1)}^*_j = \theta^{(1)}_k
    \quad \text{and} \quad \theta^{(1)}^*_i = \theta^{(1)}_i \: \forall \: i \neq k, j \\
    & \qquad \qquad \qquad \quad \theta^{(2)}^*_i = \theta^{(2)}_i \: \forall \: i \} \numberthis
\end{align*}

\begin{align*}
\label{second_neighbourhood}
    \mathcal{N}_2(\theta^{(1)}, \theta^{(2)}) &= \{ \theta^{(1)}^*, \theta^{(2)}^* \, | \, \exists \, k, j \; \text{s.t.} \;  \theta^{(2)}^*_k = \theta^{(2)}_j , \,  \theta^{(2)}^*_j = \theta^{(2)}_k
    \quad \text{and} \quad \theta^{(2)}^*_i = \theta^{(2)}_i \: \forall \: i \neq k, j \\
    & \qquad \qquad \qquad \quad \theta^{(1)}^*_i = \theta^{(1)}_i \: \forall \: i \} \numberthis
\end{align*}

\begin{align*}
\label{third_neighbourhood}
    \mathcal{N}_3(\theta^{(1)}, \theta^{(2)}) &= \{ \theta^{(1)}^*, \theta^{(2)}^* \, | \, \exists \, k, j \; \text{s.t.} \;  \theta^{(1)}^*_k = \theta^{(2)}_j , \,  \theta^{(2)}^*_j = \theta^{(1)}_k
    \quad \text{and} \quad \theta^{(2)}^*_i = \theta^{(2)}_i \: \forall \: i \neq j \\
    & \qquad \qquad \qquad \quad \theta^{(1)}^*_i = \theta^{(1)}_i \: \forall \: i \neq k \} \numberthis
\end{align*}
our neighbourhood will the union of \ref{first_neighbourhood}, \ref{second_neighbourhood} and \ref{third_neighbourhood}:

\begin{align}
    \mathcal{N}(\theta^{(1)}, \theta^{(2)}) = 
    \mathcal{N}_1(\theta^{(1)}, \theta^{(2)}) \cup
    \mathcal{N}_2(\theta^{(1)}, \theta^{(2)}) \cup
    \mathcal{N}_3(\theta^{(1)}, \theta^{(2)})
\end{align}

\noindent
\textbf{Communication:} The algorithm will then be able to reach to all possible states. This will be the case, since you can follow the following steps:\\

\noindent
Given routes/ states: $R = (R_1, R_2)$, where $R_i$ is the route for the i-th lorry. 

\begin{enumerate}
    \item First, use $\mathcal{N}_3$ to switch in all cities in $\theta^{(1)}$ that are included in $R_1$ (with either 0's or cities included in $R_2$).
    \item Second, use $\mathcal{N}_3$ to switch out all cities in $\theta^{(1)}$ that are included in $R_2$ (switch them with 0's)
    \item Then use both $\mathcal{N}_1$ and $\mathcal{N}_2$ to move all the 0's at the end of the sequence. 
    \item Last step, rearrange $(\theta^{(1)}, \theta^{(2)})$ s.t. they are equal to $R$. This can be done, as explained in exercise 4a \ref{exercise_4}.
\end{enumerate}
\noindent
We want to minimize the maximum distance that the lorries are driving. In other words, minimize the time for both of them to come back to the starting point given that all the cities have got their products. 

\section{Appendix}

\subsection{Exercise 1}
\label{exercise_1_appendix}

\subsection{Exercise 2}
\label{exercise_2_appendix}

\subsection{Exercise 2d}
\label{exercise_2_d_appendix}

\subsection{Exercise 2e}
\label{exercise_2_e_appendix}

\subsection{Exercise 2f}
\label{exercise_2_f_appendix}

\subsection{Exercise 3}
\label{exercise_3_appendix}

\subsection{Exercise 4a}
\label{exercise_4a_appendix}

\subsection{Exercise 4b}
\label{exercise_4b_appendix}

\subsection{Exercise 4d}
\label{exercise_4d_appendix}

\section{Bibliography}
\printbibliography[heading=none] 

\end{document}